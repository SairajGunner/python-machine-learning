{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSagbp9T2Oh0",
        "outputId": "f66d6978-9cc9-477a-8878-329473ca8dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "xeyKOMLQ2bfV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "unnvgXrF3AFH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "6ruynwuI2iiy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(100, input_shape=(1, ), activation = 'relu'))"
      ],
      "metadata": {
        "id": "5KlhYt3D2woU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(100, activation = 'relu'))"
      ],
      "metadata": {
        "id": "fu2I6cjz5o__"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lznx2o33GCg",
        "outputId": "4d2c8c21-56f0-4664-da6a-7af175e50ff3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               200       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10300 (40.23 KB)\n",
            "Trainable params: 10300 (40.23 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "1cQXrFvc3Y4e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGSHq3DK3jYW",
        "outputId": "1651d309-d572-40dc-d3a4-28a619e4f1e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               200       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10401 (40.63 KB)\n",
            "Trainable params: 10401 (40.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BS5tlixA3ly-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RXbO1HMG4KbN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = 2.5\n",
        "c = 3.5\n",
        "X = np.arange(-20, 20, 0.01)\n",
        "y = m*X + c + np.random.normal(0, 8.5, len(X))"
      ],
      "metadata": {
        "id": "cvi9kXzz4JZ3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.fit(X, y, epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pABBiwq4AYW",
        "outputId": "827b7890-cd18-41f8-a834-90f1b847f0d5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "125/125 [==============================] - 1s 1ms/step - loss: 197.7516 - accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 78.9981 - accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 78.7604 - accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.9671 - accuracy: 0.0000e+00\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 77.3918 - accuracy: 0.0000e+00\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 77.4664 - accuracy: 0.0000e+00\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 77.4232 - accuracy: 0.0000e+00\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.9727 - accuracy: 0.0000e+00\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3193 - accuracy: 0.0000e+00\n",
            "Epoch 10/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.7865 - accuracy: 0.0000e+00\n",
            "Epoch 11/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2532 - accuracy: 0.0000e+00\n",
            "Epoch 12/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5553 - accuracy: 0.0000e+00\n",
            "Epoch 13/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.7722 - accuracy: 0.0000e+00\n",
            "Epoch 14/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2979 - accuracy: 0.0000e+00\n",
            "Epoch 15/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0587 - accuracy: 0.0000e+00\n",
            "Epoch 16/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2364 - accuracy: 0.0000e+00\n",
            "Epoch 17/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3982 - accuracy: 0.0000e+00\n",
            "Epoch 18/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4170 - accuracy: 0.0000e+00\n",
            "Epoch 19/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5318 - accuracy: 0.0000e+00\n",
            "Epoch 20/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4287 - accuracy: 0.0000e+00\n",
            "Epoch 21/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2899 - accuracy: 0.0000e+00\n",
            "Epoch 22/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5237 - accuracy: 0.0000e+00\n",
            "Epoch 23/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0705 - accuracy: 0.0000e+00\n",
            "Epoch 24/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.6090 - accuracy: 0.0000e+00\n",
            "Epoch 25/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5061 - accuracy: 0.0000e+00\n",
            "Epoch 26/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2659 - accuracy: 0.0000e+00\n",
            "Epoch 27/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4298 - accuracy: 0.0000e+00\n",
            "Epoch 28/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3428 - accuracy: 0.0000e+00\n",
            "Epoch 29/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4079 - accuracy: 0.0000e+00\n",
            "Epoch 30/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2078 - accuracy: 0.0000e+00\n",
            "Epoch 31/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4399 - accuracy: 0.0000e+00\n",
            "Epoch 32/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3763 - accuracy: 0.0000e+00\n",
            "Epoch 33/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3094 - accuracy: 0.0000e+00\n",
            "Epoch 34/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3759 - accuracy: 0.0000e+00\n",
            "Epoch 35/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0162 - accuracy: 0.0000e+00\n",
            "Epoch 36/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 78.1951 - accuracy: 0.0000e+00\n",
            "Epoch 37/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0830 - accuracy: 0.0000e+00\n",
            "Epoch 38/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.7604 - accuracy: 0.0000e+00\n",
            "Epoch 39/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3658 - accuracy: 0.0000e+00\n",
            "Epoch 40/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2208 - accuracy: 0.0000e+00\n",
            "Epoch 41/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3793 - accuracy: 0.0000e+00\n",
            "Epoch 42/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1716 - accuracy: 0.0000e+00\n",
            "Epoch 43/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.8191 - accuracy: 0.0000e+00\n",
            "Epoch 44/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4205 - accuracy: 0.0000e+00\n",
            "Epoch 45/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2291 - accuracy: 0.0000e+00\n",
            "Epoch 46/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0031 - accuracy: 0.0000e+00\n",
            "Epoch 47/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2145 - accuracy: 0.0000e+00\n",
            "Epoch 48/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2686 - accuracy: 0.0000e+00\n",
            "Epoch 49/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.6484 - accuracy: 0.0000e+00\n",
            "Epoch 50/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3929 - accuracy: 0.0000e+00\n",
            "Epoch 51/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2704 - accuracy: 0.0000e+00\n",
            "Epoch 52/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4762 - accuracy: 0.0000e+00\n",
            "Epoch 53/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5243 - accuracy: 0.0000e+00\n",
            "Epoch 54/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2768 - accuracy: 0.0000e+00\n",
            "Epoch 55/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5465 - accuracy: 0.0000e+00\n",
            "Epoch 56/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2193 - accuracy: 0.0000e+00\n",
            "Epoch 57/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3966 - accuracy: 0.0000e+00\n",
            "Epoch 58/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3942 - accuracy: 0.0000e+00\n",
            "Epoch 59/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2917 - accuracy: 0.0000e+00\n",
            "Epoch 60/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5799 - accuracy: 0.0000e+00\n",
            "Epoch 61/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2326 - accuracy: 0.0000e+00\n",
            "Epoch 62/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5056 - accuracy: 0.0000e+00\n",
            "Epoch 63/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4319 - accuracy: 0.0000e+00\n",
            "Epoch 64/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3506 - accuracy: 0.0000e+00\n",
            "Epoch 65/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1199 - accuracy: 0.0000e+00\n",
            "Epoch 66/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4581 - accuracy: 0.0000e+00\n",
            "Epoch 67/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1898 - accuracy: 0.0000e+00\n",
            "Epoch 68/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9307 - accuracy: 0.0000e+00\n",
            "Epoch 69/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3039 - accuracy: 0.0000e+00\n",
            "Epoch 70/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3181 - accuracy: 0.0000e+00\n",
            "Epoch 71/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2052 - accuracy: 0.0000e+00\n",
            "Epoch 72/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4223 - accuracy: 0.0000e+00\n",
            "Epoch 73/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5680 - accuracy: 0.0000e+00\n",
            "Epoch 74/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1337 - accuracy: 0.0000e+00\n",
            "Epoch 75/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.7006 - accuracy: 0.0000e+00\n",
            "Epoch 76/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.6951 - accuracy: 0.0000e+00\n",
            "Epoch 77/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0643 - accuracy: 0.0000e+00\n",
            "Epoch 78/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0421 - accuracy: 0.0000e+00\n",
            "Epoch 79/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1833 - accuracy: 0.0000e+00\n",
            "Epoch 80/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 77.7503 - accuracy: 0.0000e+00\n",
            "Epoch 81/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 77.1008 - accuracy: 0.0000e+00\n",
            "Epoch 82/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 77.2031 - accuracy: 0.0000e+00\n",
            "Epoch 83/150\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 77.1180 - accuracy: 0.0000e+00\n",
            "Epoch 84/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4674 - accuracy: 0.0000e+00\n",
            "Epoch 85/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1380 - accuracy: 0.0000e+00\n",
            "Epoch 86/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2564 - accuracy: 0.0000e+00\n",
            "Epoch 87/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1161 - accuracy: 0.0000e+00\n",
            "Epoch 88/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1542 - accuracy: 0.0000e+00\n",
            "Epoch 89/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3737 - accuracy: 0.0000e+00\n",
            "Epoch 90/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5398 - accuracy: 0.0000e+00\n",
            "Epoch 91/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2853 - accuracy: 0.0000e+00\n",
            "Epoch 92/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3445 - accuracy: 0.0000e+00\n",
            "Epoch 93/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2688 - accuracy: 0.0000e+00\n",
            "Epoch 94/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5768 - accuracy: 0.0000e+00\n",
            "Epoch 95/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2387 - accuracy: 0.0000e+00\n",
            "Epoch 96/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3279 - accuracy: 0.0000e+00\n",
            "Epoch 97/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9998 - accuracy: 0.0000e+00\n",
            "Epoch 98/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.7481 - accuracy: 0.0000e+00\n",
            "Epoch 99/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0963 - accuracy: 0.0000e+00\n",
            "Epoch 100/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4638 - accuracy: 0.0000e+00\n",
            "Epoch 101/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3075 - accuracy: 0.0000e+00\n",
            "Epoch 102/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1884 - accuracy: 0.0000e+00\n",
            "Epoch 103/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2130 - accuracy: 0.0000e+00\n",
            "Epoch 104/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4887 - accuracy: 0.0000e+00\n",
            "Epoch 105/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5484 - accuracy: 0.0000e+00\n",
            "Epoch 106/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4678 - accuracy: 0.0000e+00\n",
            "Epoch 107/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9174 - accuracy: 0.0000e+00\n",
            "Epoch 108/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1320 - accuracy: 0.0000e+00\n",
            "Epoch 109/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3010 - accuracy: 0.0000e+00\n",
            "Epoch 110/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0731 - accuracy: 0.0000e+00\n",
            "Epoch 111/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2253 - accuracy: 0.0000e+00\n",
            "Epoch 112/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2155 - accuracy: 0.0000e+00\n",
            "Epoch 113/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3688 - accuracy: 0.0000e+00\n",
            "Epoch 114/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0647 - accuracy: 0.0000e+00\n",
            "Epoch 115/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.6130 - accuracy: 0.0000e+00\n",
            "Epoch 116/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.5443 - accuracy: 0.0000e+00\n",
            "Epoch 117/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3626 - accuracy: 0.0000e+00\n",
            "Epoch 118/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.7900 - accuracy: 0.0000e+00\n",
            "Epoch 119/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3146 - accuracy: 0.0000e+00\n",
            "Epoch 120/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4195 - accuracy: 0.0000e+00\n",
            "Epoch 121/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4662 - accuracy: 0.0000e+00\n",
            "Epoch 122/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0075 - accuracy: 0.0000e+00\n",
            "Epoch 123/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2918 - accuracy: 0.0000e+00\n",
            "Epoch 124/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9327 - accuracy: 0.0000e+00\n",
            "Epoch 125/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4257 - accuracy: 0.0000e+00\n",
            "Epoch 126/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3703 - accuracy: 0.0000e+00\n",
            "Epoch 127/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0055 - accuracy: 0.0000e+00\n",
            "Epoch 128/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4473 - accuracy: 0.0000e+00\n",
            "Epoch 129/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2157 - accuracy: 0.0000e+00\n",
            "Epoch 130/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9752 - accuracy: 0.0000e+00\n",
            "Epoch 131/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2844 - accuracy: 0.0000e+00\n",
            "Epoch 132/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3080 - accuracy: 0.0000e+00\n",
            "Epoch 133/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1222 - accuracy: 0.0000e+00\n",
            "Epoch 134/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3847 - accuracy: 0.0000e+00\n",
            "Epoch 135/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1650 - accuracy: 0.0000e+00\n",
            "Epoch 136/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0330 - accuracy: 0.0000e+00\n",
            "Epoch 137/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1505 - accuracy: 0.0000e+00\n",
            "Epoch 138/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.4300 - accuracy: 0.0000e+00\n",
            "Epoch 139/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9920 - accuracy: 0.0000e+00\n",
            "Epoch 140/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3332 - accuracy: 0.0000e+00\n",
            "Epoch 141/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2754 - accuracy: 0.0000e+00\n",
            "Epoch 142/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9709 - accuracy: 0.0000e+00\n",
            "Epoch 143/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1096 - accuracy: 0.0000e+00\n",
            "Epoch 144/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.0818 - accuracy: 0.0000e+00\n",
            "Epoch 145/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.3709 - accuracy: 0.0000e+00\n",
            "Epoch 146/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.1651 - accuracy: 0.0000e+00\n",
            "Epoch 147/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2481 - accuracy: 0.0000e+00\n",
            "Epoch 148/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9262 - accuracy: 0.0000e+00\n",
            "Epoch 149/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 77.2293 - accuracy: 0.0000e+00\n",
            "Epoch 150/150\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 76.9726 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h.history['loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGrCMK7Q41Am",
        "outputId": "4232c5a1-bb9e-40af-aa81-d675682f51f1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[197.7515869140625,\n",
              " 78.99809265136719,\n",
              " 78.76039123535156,\n",
              " 77.96707916259766,\n",
              " 77.39176940917969,\n",
              " 77.46644592285156,\n",
              " 77.42324829101562,\n",
              " 77.97268676757812,\n",
              " 77.31932830810547,\n",
              " 77.78645324707031,\n",
              " 77.25316619873047,\n",
              " 77.55528259277344,\n",
              " 77.77217102050781,\n",
              " 77.29792022705078,\n",
              " 77.05873107910156,\n",
              " 77.23635864257812,\n",
              " 77.39815521240234,\n",
              " 77.41696166992188,\n",
              " 77.53175354003906,\n",
              " 77.42867279052734,\n",
              " 77.28990936279297,\n",
              " 77.52365112304688,\n",
              " 77.07052612304688,\n",
              " 77.60901641845703,\n",
              " 77.5060806274414,\n",
              " 77.26592254638672,\n",
              " 77.4298324584961,\n",
              " 77.34284973144531,\n",
              " 77.4079360961914,\n",
              " 77.20781707763672,\n",
              " 77.43985748291016,\n",
              " 77.37625885009766,\n",
              " 77.3094482421875,\n",
              " 77.37589263916016,\n",
              " 77.01618194580078,\n",
              " 78.19509887695312,\n",
              " 77.08303833007812,\n",
              " 77.7603530883789,\n",
              " 77.36576080322266,\n",
              " 77.22078704833984,\n",
              " 77.37926483154297,\n",
              " 77.17162322998047,\n",
              " 77.81906127929688,\n",
              " 77.42054748535156,\n",
              " 77.2291488647461,\n",
              " 77.00309753417969,\n",
              " 77.21453857421875,\n",
              " 77.26863861083984,\n",
              " 77.64839172363281,\n",
              " 77.39293670654297,\n",
              " 77.2703857421875,\n",
              " 77.47622680664062,\n",
              " 77.52426147460938,\n",
              " 77.27677154541016,\n",
              " 77.54651641845703,\n",
              " 77.21930694580078,\n",
              " 77.39657592773438,\n",
              " 77.39420318603516,\n",
              " 77.29168701171875,\n",
              " 77.57994079589844,\n",
              " 77.23258972167969,\n",
              " 77.50564575195312,\n",
              " 77.43187713623047,\n",
              " 77.35061645507812,\n",
              " 77.11993408203125,\n",
              " 77.45806884765625,\n",
              " 77.18983459472656,\n",
              " 76.93065643310547,\n",
              " 77.30393981933594,\n",
              " 77.31808471679688,\n",
              " 77.2052230834961,\n",
              " 77.4223403930664,\n",
              " 77.56797790527344,\n",
              " 77.13370513916016,\n",
              " 77.70061492919922,\n",
              " 77.69509887695312,\n",
              " 77.06427764892578,\n",
              " 77.04208374023438,\n",
              " 77.18334197998047,\n",
              " 77.75029754638672,\n",
              " 77.10082244873047,\n",
              " 77.20313262939453,\n",
              " 77.11798095703125,\n",
              " 77.46744537353516,\n",
              " 77.1380386352539,\n",
              " 77.25636291503906,\n",
              " 77.11611938476562,\n",
              " 77.15422058105469,\n",
              " 77.37372589111328,\n",
              " 77.53984832763672,\n",
              " 77.2852554321289,\n",
              " 77.34453582763672,\n",
              " 77.26876831054688,\n",
              " 77.57677459716797,\n",
              " 77.2386703491211,\n",
              " 77.32788848876953,\n",
              " 76.99976348876953,\n",
              " 77.74810791015625,\n",
              " 77.09632110595703,\n",
              " 77.46378326416016,\n",
              " 77.3074722290039,\n",
              " 77.18836212158203,\n",
              " 77.21302032470703,\n",
              " 77.48873901367188,\n",
              " 77.54839324951172,\n",
              " 77.4677505493164,\n",
              " 76.91744995117188,\n",
              " 77.13198852539062,\n",
              " 77.3010025024414,\n",
              " 77.0730972290039,\n",
              " 77.2253189086914,\n",
              " 77.21554565429688,\n",
              " 77.3687515258789,\n",
              " 77.0647201538086,\n",
              " 77.61299896240234,\n",
              " 77.54427337646484,\n",
              " 77.3626480102539,\n",
              " 76.78996276855469,\n",
              " 77.3145523071289,\n",
              " 77.41949462890625,\n",
              " 77.4662094116211,\n",
              " 77.00749206542969,\n",
              " 77.2917709350586,\n",
              " 76.93265533447266,\n",
              " 77.42572021484375,\n",
              " 77.37025451660156,\n",
              " 77.0055160522461,\n",
              " 77.44728088378906,\n",
              " 77.21569061279297,\n",
              " 76.97521209716797,\n",
              " 77.2844467163086,\n",
              " 77.30802154541016,\n",
              " 77.12222290039062,\n",
              " 77.38472747802734,\n",
              " 77.1650390625,\n",
              " 77.03301239013672,\n",
              " 77.15054321289062,\n",
              " 77.43003845214844,\n",
              " 76.99198913574219,\n",
              " 77.33322143554688,\n",
              " 77.27543640136719,\n",
              " 76.97089385986328,\n",
              " 77.10956573486328,\n",
              " 77.08182525634766,\n",
              " 77.3708724975586,\n",
              " 77.16505432128906,\n",
              " 77.24811553955078,\n",
              " 76.9262466430664,\n",
              " 77.2292709350586,\n",
              " 76.97258758544922]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}